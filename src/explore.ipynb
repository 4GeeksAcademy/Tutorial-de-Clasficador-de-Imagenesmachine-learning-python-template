{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Explore here"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "\n",
                "import os\n",
                "import shutil\n",
                "\n",
                "from sklearn.model_selection import train_test_split\n",
                "import matplotlib.pyplot as plt\n",
                "from tensorflow import keras\n",
                "from keras.preprocessing import image\n",
                "from keras.src.legacy.preprocessing.image import ImageDataGenerator\n",
                "\n",
                "from keras.models import Sequential\n",
                "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Sistema de clasificación de imágenes\n",
                "\n",
                "El conjunto de datos se compone de fotos de perros y gatos proporcionadas como un subconjunto de fotos de uno mucho más grande de 3 millones de fotos anotadas manualmente. Estos datos se obtuvieron a través de una colaboración entre Petfinder.com y Microsoft.\n",
                "\n",
                "El conjunto de datos se usó originalmente como un CAPTCHA, es decir, una tarea que se cree que un humano encuentra trivial, pero que una máquina no puede resolver, que se usa en sitios web para distinguir entre usuarios humanos y bots. La tarea se denominó \"Asirra\". Cuando se presentó \"Asirra\", se mencionó \"que los estudios de usuarios indican que los humanos pueden resolverlo el 99,6% de las veces en menos de 30 segundos\". A menos que se produzca un gran avance en la visión artificial, esperamos que los ordenadores no tengan más de 1/54.000 posibilidades de resolverlo.\n",
                "\n",
                "En el momento en que se publicó la competencia, el resultado de última generación se logró con un SVM y se describió en un artículo de 2007 con el título \"Ataques de Machine Learning contra el CAPTCHA de Asirra\" (PDF) que logró una precisión de clasificación del 80%. Fue este documento el que demostró que la tarea ya no era una tarea adecuada para un CAPTCHA poco después de que se propusiera la tarea.\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Paso 1: Carga del conjunto de datos\n",
                "\n",
                "El conjunto de datos se encuentra en este link. Descarga la carpeta y descomprime los archivos. Ahora tendrás una carpeta con el dataset y una carpeta llamada train que contiene más de 25.000 archivos de imagen (formato .jpg) de perros y gatos. Las fotos están etiquetadas por su nombre de archivo, con la palabra dog o cat.\n",
                " - 1. Definir la ruta de acceso a las imágenes\n",
                " "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_dir = \"C:/Users/ANTONIO/Downloads/dogs-vs-cats/train\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Paso 2: Visualiza la información de entrada\n",
                "El primer paso cuando nos enfrentamos a un problema de clasificación de imágenes es obtener toda la información posible a través de ellas. Por lo tanto, carga e imprime las primeras nueve fotos de perros en una sola figura. Repite lo mismo para los gatos. Puedes ver que las fotos son a color y tienen diferentes formas y tamaños.\n",
                "\n",
                "Esta variedad de tamaños y formatos debe solucionarse antes de entrenar el modelo. Asegúrate de que todas tengan un tamaño fijo de 200x200 píxeles.\n",
                "\n",
                "Como podrás ver, son una gran cantidad de imágenes, asegúrate de seguir las siguientes normas:\n",
                "\n",
                "Si tienes más de 12 gigabytes de RAM, usa la API de procesamiento de imágenes de Keras para cargar las 25.000 fotos en el conjunto de datos de entrenamiento y remodelarlas a fotos cuadradas de 200×200 píxeles. La etiqueta también debe determinarse para cada foto en función de los nombres de archivo. Se debe guardar una tupla de fotos y etiquetas.\n",
                "Si no tienes más de 12 gigabytes de RAM, carga las imágenes progresivamente usando la clase Keras ImageDataGenerator y la función flow_from_directory(). Esto será más lento de ejecutar, pero se ejecutará en hardware de menor capacidad. Esta función prefiere que los datos se dividan en directorios train y test separados, y debajo de cada directorio para tener un subdirectorio para cada clase.\n",
                "Una vez tengas todas las imágenes procesadas, crea un objeto ImageDataGenerator para datos de entrenamiento y prueba. Luego pasa la carpeta que tiene datos de entrenamiento al objeto trdata y, de manera similar, pasa la carpeta que tiene datos de prueba al objeto tsdata. De esta forma, se etiquetarán las imágenes automáticamente y estará todo listo para entrar a la red."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Ignorando carpeta: cat\n",
                        "Ignorando carpeta: dog\n",
                        "Movimiento completado.\n"
                    ]
                }
            ],
            "source": [
                "train_dir = \"C:/Users/ANTONIO/Downloads/dogs-vs-cats/train\"\n",
                "\n",
                "cat_dir = os.path.join(train_dir, \"cat\")\n",
                "dog_dir = os.path.join(train_dir, \"dog\")\n",
                "\n",
                "# Crear carpetas si no existen\n",
                "os.makedirs(cat_dir, exist_ok=True)\n",
                "os.makedirs(dog_dir, exist_ok=True)\n",
                "\n",
                "for filename in os.listdir(train_dir):\n",
                "    file_path = os.path.join(train_dir, filename)\n",
                "\n",
                "    # Ignorar carpetas\n",
                "    if os.path.isdir(file_path):\n",
                "        print(\"Ignorando carpeta:\", filename)\n",
                "        continue\n",
                "\n",
                "    # Mover solo archivos JPG reales\n",
                "    if filename.lower().startswith(\"cat\") and filename.lower().endswith(\".jpg\"):\n",
                "        shutil.move(file_path, os.path.join(cat_dir, filename))\n",
                "\n",
                "    elif filename.lower().startswith(\"dog\") and filename.lower().endswith(\".jpg\"):\n",
                "        shutil.move(file_path, os.path.join(dog_dir, filename))\n",
                "\n",
                "print(\"Movimiento completado.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "PERROS: 0\n",
                        "GATOS: 0\n"
                    ]
                }
            ],
            "source": [
                "dog_dir = \"C:/Users/ANTONIO/Downloads/dogs-vs-cats/train/dog\"\n",
                "cat_dir = \"C:/Users/ANTONIO/Downloads/dogs-vs-cats/train/cat\"\n",
                "\n",
                "print(\"PERROS:\", len(os.listdir(dog_dir)))\n",
                "print(\"GATOS:\", len(os.listdir(cat_dir)))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Perros "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "ename": "IndexError",
                    "evalue": "list index out of range",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m dog_images = []\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m9\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     img_path = os.path.join(dog_dir, \u001b[43mdog_files\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[32m     10\u001b[39m     img = image.load_img(img_path)\n\u001b[32m     11\u001b[39m     img_arr = image.img_to_array(img)\n",
                        "\u001b[31mIndexError\u001b[39m: list index out of range"
                    ]
                }
            ],
            "source": [
                "\n",
                "dog_dir = \"C:/Users/ANTONIO/Downloads/dogs-vs-cats/train/dog\"\n",
                "\n",
                "dog_files = os.listdir(dog_dir)\n",
                "dog_files = [f for f in dog_files if f.endswith(\".jpg\")]\n",
                "\n",
                "dog_images = []\n",
                "\n",
                "for i in range(9):\n",
                "    img_path = os.path.join(dog_dir, dog_files[i])\n",
                "    img = image.load_img(img_path)\n",
                "    img_arr = image.img_to_array(img)\n",
                "    dog_images.append(img_arr)\n",
                "\n",
                "plt.figure(figsize=(10, 10))\n",
                "\n",
                "for i in range(9):\n",
                "    plt.subplot(3, 3, i+1)\n",
                "    plt.imshow(dog_images[i].astype(\"uint8\"))\n",
                "    plt.axis('off')\n",
                "    plt.title(f\"Dog {i+1}\")\n",
                "\n",
                "plt.show()\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- Carga de las imágenes con keras.\n",
                "  - Defiimos la ruta \n",
                "  - Guardamos en una variable el tamaño de las imágenes\n",
                "  - En otra variables guardamos el procesamiento o generador de las imágenes que se van a ir procesando poco a poco en la red neuronal."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "# Define a few rules for DataGen\n",
                "entrenamineto_dir = \"C:/Users/ANTONIO/Downloads/dogs-vs-cats/train\"\n",
                "tamano_img = (200, 200)\n",
                "\n",
                "generador_train = ImageDataGenerator()\n",
                "generador_test = ImageDataGenerator()\n",
                "\n",
                "\n",
                "\n",
                "train_data = generador_train.flow_from_directory(\n",
                "    entrenamineto_dir,\n",
                "    target_size = tamano_img,\n",
                "    classes = [\"dog\", \"cat\"] \n",
                ")\n",
                "\n",
                "\n",
                "test_data = generador_test.flow_from_directory(\n",
                "    entrenamineto_dir,\n",
                "    target_size = tamano_img,\n",
                "    classes = [\"test\"] \n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Entrenar Modelo "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model = Sequential()\n",
                "model.add(Conv2D(input_shape = (224,224,3), filters = 64, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(Conv2D(filters = 64,kernel_size = (3,3),padding = \"same\", activation = \"relu\"))\n",
                "model.add(MaxPool2D(pool_size = (2,2),strides = (2,2)))\n",
                "model.add(Conv2D(filters = 128, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(Conv2D(filters = 128, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(MaxPool2D(pool_size = (2,2),strides = (2,2)))\n",
                "model.add(Conv2D(filters = 256, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(Conv2D(filters = 256, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(Conv2D(filters = 256, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(MaxPool2D(pool_size = (2,2),strides = (2,2)))\n",
                "model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(MaxPool2D(pool_size = (2,2),strides = (2,2)))\n",
                "model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(Conv2D(filters = 512, kernel_size = (3,3), padding = \"same\", activation = \"relu\"))\n",
                "model.add(MaxPool2D(pool_size = (2,2),strides = (2,2)))\n",
                "model.add(Flatten())\n",
                "model.add(Dense(units = 4096,activation = \"relu\"))\n",
                "model.add(Dense(units = 4096,activation = \"relu\"))\n",
                "model.add(Dense(units = 2, activation = \"softmax\"))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.2"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
